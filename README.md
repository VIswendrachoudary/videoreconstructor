ğŸ¥ **Jumbled Video Reconstruction Challenge**

This project restores the original order of a 10-second, 1080p (30 FPS) video whose frames have been randomly shuffled.
It leverages deep visual similarity (ResNet-18) and feature coherence to rebuild the temporal sequence accurately.

---

## ğŸ§© Objective

Given a shuffled video (`data/jumbled_video.mp4`), the system:

1. Extracts individual frames
2. Generates visual embeddings using a pretrained ResNet-18 model
3. Infers the correct sequential frame order
4. Rebuilds the video in its original motion flow

---

## âš™ï¸ Requirements

**Python 3.8+**

Install dependencies before running any scripts:

pip install opencv-python tqdm numpy torch torchvision pillow

---

## ğŸ“ Project Structure

data/
â”‚â”€â”€ jumbled_video.mp4
â”‚â”€â”€ frames_jumbled/
â”‚â”€â”€ frame_features.npy
â”‚â”€â”€ frame_order_final.npy

output/
â”‚â”€â”€ reconstructed_video_final_smooth.mp4

extract_frames.py
extract_features.py
reconstruct_sequence.py
rebuild_video.py
README.md

ğŸ’¡ Tip:
If `data/` or `output/` folders donâ€™t exist, create them manually before running the scripts.

---

## ğŸš€ Usage & Execution Order

1ï¸âƒ£ **Extract Frames**

Extract all frames from the input video.

python extract_frames.py
Input: data/jumbled_video.mp4
Output: data/frames_jumbled/frame_0000.jpg â€¦

---

2ï¸âƒ£ **Extract Frame Features**

Generate and save 512-D feature vectors using ResNet-18.

python extract_features.py
Input: data/frames_jumbled/
Output: data/frame_features.npy

---

3ï¸âƒ£ **Generate Frame Order**

Create the correct order file (frame_order_final.npy).
This step may use custom logic or a separate similarity model.

python reconstruct_sequence.py
Input: data/frames_jumbled/
Output: data/frame_order_final.npy

---

4ï¸âƒ£ **Rebuild the Video**

Reconstruct the final smooth video in the correct order.

python rebuild_video.py
Inputs:
â€¢ data/frames_jumbled/
â€¢ data/frame_order_final.npy

Output: output/reconstructed_video_final_smooth.mp4

Execution time is logged automatically in execution_time.txt.

---

## ğŸ§  Key Design Choices

Feature Embedding: ResNet-18 (ImageNet pretrained) â†’ Captures spatial-semantic frame similarity
Matching Logic: Pairwise feature similarity â†’ Infers temporal coherence
Optimization: GPU acceleration, batch processing â†’ Speed & scalability
Modularity: Independent stages â†’ Easy debugging & upgrades

---

## ğŸ§® Complexity (Approx.)

Feature extraction â€“ O(N)
Similarity computation â€“ O(NÂ²)
Sorting / reconstruction â€“ O(N log N)

For 300 frames, runtime typically stays within a few seconds on a GPU-enabled system.

---

## âš¡ Optimization & Parallelism

â€¢ CUDA auto-use when available
â€¢ Batch inference for efficient tensor ops
â€¢ Vectorized NumPy for similarity computation
â€¢ Ready for multiprocessing extensions

---

## ğŸ§© Limitations & Future Work

â€¢ Nearly identical frames can confuse ordering
â€¢ Optical flow or temporal CNNs could enhance stability
â€¢ Graph-based order inference may yield global consistency

---

## ğŸ¯ Output

âœ… Reconstructed video: output/reconstructed_video_final_smooth.mp4
ğŸ•’ Execution log: execution_time.txt
ğŸ“Š Metrics: Frame continuity, average similarity (%), runtime efficiency

---

## ğŸ Result

The system reconstructs the shuffled video with near-original motion, preserving smooth transitions and temporal integrity.

---

## ğŸ“˜ Algorithm Explanation

**Step 1 â€“ Frame Extraction**
Using OpenCV, every frame is stored sequentially for processing.

**Step 2 â€“ Feature Extraction**
Each frame passes through ResNet-18 (pretrained on ImageNet).
The classifier head is removed to obtain a 512-D visual embedding per frame.
All embeddings are saved in frame_features.npy.

**Step 3 â€“ Sequence Reconstruction**
A predicted order (frame_order_final.npy) is generated based on pairwise feature similarity â€”
frames that look alike and follow motion cues are placed adjacently.
Local smoothing fixes sharp jumps; reversal detection ensures forward playback.

**Step 4 â€“ Video Rebuilding**
Frames are reassembled using OpenCVâ€™s VideoWriter.
Frame continuity and order statistics are printed for quick verification.

---

## âš™ï¸ Optimization Details

GPU Acceleration â€“ CUDA used automatically when available
Batch Processing â€“ Reduces read/write overhead
Vectorized Math â€“ NumPy replaces explicit Python loops
Parallel Extensions â€“ Ready for multiprocessing on larger datasets

---

## ğŸ’¡ Design Considerations

Accuracy â€“ Deep visual embeddings capture semantics and color
Speed â€“ ResNet-18 balances detail vs. runtime
Robustness â€“ Order smoothing & reversal check avoid local misalignments
Scalability â€“ Modular design supports easy extension

---

## â±ï¸ Time Complexity (Approx.)

Feature extraction â€“ O(N)
Pairwise similarity â€“ O(NÂ²)
Sorting / reconstruction â€“ O(N log N)

For 300 frames, runtime stays within a few seconds on the benchmark system.

---

## ğŸš§ Limitations & Future Work

â€¢ Nearly identical frames can confuse ordering
â€¢ Could be enhanced with optical flow or temporal CNNs
â€¢ Future versions may use graph traversal for global order inference

---

## âœ… Result

The reconstructed video closely matches the original temporal flow, maintaining natural motion and minimizing frame discontinuities.

---

End of Document âœ…
